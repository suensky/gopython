{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_openml\n",
    "X, y = fetch_openml('mnist_784', version=1, parser='auto', return_X_y=True)\n",
    "X = X.values\n",
    "y = y.astype(int).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(70000, 784)\n",
      "(70000,)\n",
      "[5 0 4 1 9 2 1 3 1 4]\n"
     ]
    }
   ],
   "source": [
    "print(X.shape)\n",
    "print(y.shape)\n",
    "print(y[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 10 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "fig, ax = plt.subplots(nrows=2, ncols=5,\n",
    "                       sharex=True, sharey=True)\n",
    "ax = ax.flatten()\n",
    "for i in range(10):\n",
    "    img = X[i].reshape(28, 28)\n",
    "    ax[i].imshow(img, cmap='Greys')\n",
    "# ax[0].set_xticks([])\n",
    "# ax[0].set_yticks([])\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def printNum(num, rows=5, cols=5):\n",
    "    fig, ax = plt.subplots(nrows=rows, ncols=cols, sharex=True, sharey=True)\n",
    "    ax = ax.flatten()\n",
    "\n",
    "    total_imgs = rows * cols\n",
    "    X_filter_for_num = X[y == num]\n",
    "    for i in range(total_imgs):\n",
    "        img = X_filter_for_num[i].reshape(28, 28)\n",
    "        ax[i].imshow(img, cmap='Greys')\n",
    "\n",
    "    ax[0].set_xticks([])\n",
    "    ax[0].set_yticks([])\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(10):\n",
    "    printNum(i)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split to get Test dataset\n",
    "X_temp, X_test, y_temp, y_test = train_test_split(X, y, test_size=10000, random_state=123, stratify=y)\n",
    "\n",
    "# Split X_temp into train and validation datasets\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X_temp, y_temp, test_size=5000, random_state=123, stratify=y_temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Activation function\n",
    "def sigmoid(z):\n",
    "    return 1. / (1. + np.exp(-z))\n",
    "\n",
    "# One hot\n",
    "def int_to_onehot(y, num_labels):\n",
    "    ary = np.zeros((y.shape[0], num_labels))\n",
    "    for i, val in enumerate(y):\n",
    "        ary[i, val] = 1\n",
    "    return ary\n",
    "\n",
    "class NeuralNetMLP:\n",
    "    def __init__(self, num_features, num_hidden, num_classes, random_seed=123) -> None:\n",
    "        super().__init__()\n",
    "\n",
    "        self.num_classes = num_classes\n",
    "\n",
    "        # hidden layer\n",
    "        rng = np.random.RandomState(random_seed)\n",
    "        self.weight_h = rng.normal(loc=0.0, scale=0.1, size=(num_hidden, num_features))\n",
    "        self.bias_h = np.zeros(num_hidden)\n",
    "\n",
    "        # output\n",
    "        self.weight_output = rng.normal(loc=0., scale=.1, size=(num_classes, num_hidden))\n",
    "        self.bias_output = np.zeros(num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Hidden layer\n",
    "        # input dim:  num_examples * num_features\n",
    "        # weight dim: num_hidden * num_features\n",
    "        # weight.T dim: num_features * num_hidden\n",
    "        # output dim: num_examples * num_hidden\n",
    "        z_h = np.dot(x, self.weight_h.T) + self.bias_h\n",
    "        a_h = sigmoid(z_h)\n",
    "\n",
    "        # Output layer\n",
    "        # input dim: num_exmaples * num_hidden\n",
    "        # weight dim: num_classes * num_hidden\n",
    "        # weight.T dim: n_hidden * num_classes\n",
    "        # output dim: num_examples * num_classes\n",
    "        z_out = np.dot(a_h, self.weight_output.T) + self.bias_output\n",
    "        a_out = sigmoid(z_out)\n",
    "        return a_h, a_out\n",
    "    \n",
    "    def backward(self, x, a_h, a_out, y):  \n",
    "    \n",
    "        #########################\n",
    "        ### Output layer weights\n",
    "        #########################\n",
    "        \n",
    "        # onehot encoding\n",
    "        y_onehot = int_to_onehot(y, self.num_classes)\n",
    "\n",
    "        # Part 1: dLoss/dOutWeights\n",
    "        ## = dLoss/dOutAct * dOutAct/dOutNet * dOutNet/dOutWeight\n",
    "        ## where DeltaOut = dLoss/dOutAct * dOutAct/dOutNet\n",
    "        ## for convenient re-use\n",
    "        \n",
    "        # input/output dim: [n_examples, n_classes]\n",
    "        d_loss__d_a_out = 2.*(a_out - y_onehot) / y.shape[0]\n",
    "\n",
    "        # input/output dim: [n_examples, n_classes]\n",
    "        d_a_out__d_z_out = a_out * (1. - a_out) # sigmoid derivative\n",
    "\n",
    "        # output dim: [n_examples, n_classes]\n",
    "        delta_out = d_loss__d_a_out * d_a_out__d_z_out # \"delta (rule) placeholder\"\n",
    "\n",
    "        # gradient for output weights\n",
    "        \n",
    "        # [n_examples, n_hidden]\n",
    "        d_z_out__dw_out = a_h\n",
    "        \n",
    "        # input dim: [n_classes, n_examples] dot [n_examples, n_hidden]\n",
    "        # output dim: [n_classes, n_hidden]\n",
    "        d_loss__dw_out = np.dot(delta_out.T, d_z_out__dw_out)\n",
    "        d_loss__db_out = np.sum(delta_out, axis=0)\n",
    "        \n",
    "\n",
    "        #################################        \n",
    "        # Part 2: dLoss/dHiddenWeights\n",
    "        ## = DeltaOut * dOutNet/dHiddenAct * dHiddenAct/dHiddenNet * dHiddenNet/dWeight\n",
    "        \n",
    "        # [n_classes, n_hidden]\n",
    "        d_z_out__a_h = self.weight_output\n",
    "        \n",
    "        # output dim: [n_examples, n_hidden]\n",
    "        d_loss__a_h = np.dot(delta_out, d_z_out__a_h)\n",
    "        \n",
    "        # [n_examples, n_hidden]\n",
    "        d_a_h__d_z_h = a_h * (1. - a_h) # sigmoid derivative\n",
    "        \n",
    "        # [n_examples, n_features]\n",
    "        d_z_h__d_w_h = x\n",
    "        \n",
    "        # output dim: [n_hidden, n_features]\n",
    "        d_loss__d_w_h = np.dot((d_loss__a_h * d_a_h__d_z_h).T, d_z_h__d_w_h)\n",
    "        d_loss__d_b_h = np.sum((d_loss__a_h * d_a_h__d_z_h), axis=0)\n",
    "\n",
    "        return (d_loss__dw_out, d_loss__db_out, \n",
    "                d_loss__d_w_h, d_loss__d_b_h)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = NeuralNetMLP(num_features=28*28,\n",
    "                     num_hidden=50,\n",
    "                     num_classes=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100, 784)\n",
      "(100,)\n",
      "Initial validation MSE: 0.2\n",
      "Initial validation accuracy: 11.2%\n",
      "Initial valid MSE: 0.2\n",
      "Initial valid accuracy: 11.2%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/gh/_rn0mj6977n_tj3zkksxl7mc0000gn/T/ipykernel_17444/2250388816.py:5: RuntimeWarning: overflow encountered in exp\n",
      "  return 1. / (1. + np.exp(-z))\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 50\n",
    "minibatch_size = 100\n",
    "\n",
    "\n",
    "def minibatch_generator(X, y, minibatch_size):\n",
    "    indices = np.arange(X.shape[0])\n",
    "    np.random.shuffle(indices)\n",
    "\n",
    "    for start_idx in range(0, indices.shape[0] - minibatch_size \n",
    "                           + 1, minibatch_size):\n",
    "        batch_idx = indices[start_idx:start_idx + minibatch_size]\n",
    "        \n",
    "        yield X[batch_idx], y[batch_idx]\n",
    "\n",
    "        \n",
    "# iterate over training epochs\n",
    "for i in range(num_epochs):\n",
    "\n",
    "    # iterate over minibatches\n",
    "    minibatch_gen = minibatch_generator(\n",
    "        X_train, y_train, minibatch_size)\n",
    "    \n",
    "    for X_train_mini, y_train_mini in minibatch_gen:\n",
    "\n",
    "        break\n",
    "        \n",
    "    break\n",
    "    \n",
    "print(X_train_mini.shape)\n",
    "print(y_train_mini.shape)\n",
    "\n",
    "\n",
    "# Defining a function to compute the loss and accuracy\n",
    "\n",
    "\n",
    "\n",
    "def mse_loss(targets, probas, num_labels=10):\n",
    "    onehot_targets = int_to_onehot(targets, num_labels=num_labels)\n",
    "    return np.mean((onehot_targets - probas)**2)\n",
    "\n",
    "\n",
    "def accuracy(targets, predicted_labels):\n",
    "    return np.mean(predicted_labels == targets) \n",
    "\n",
    "\n",
    "_, probas = model.forward(X_valid)\n",
    "mse = mse_loss(y_valid, probas)\n",
    "\n",
    "predicted_labels = np.argmax(probas, axis=1)\n",
    "acc = accuracy(y_valid, predicted_labels)\n",
    "\n",
    "print(f'Initial validation MSE: {mse:.1f}')\n",
    "print(f'Initial validation accuracy: {acc*100:.1f}%')\n",
    "\n",
    "\n",
    "def compute_mse_and_acc(nnet, X, y, num_labels=10, minibatch_size=100):\n",
    "    mse, correct_pred, num_examples = 0., 0, 0\n",
    "    minibatch_gen = minibatch_generator(X, y, minibatch_size)\n",
    "        \n",
    "    for i, (features, targets) in enumerate(minibatch_gen):\n",
    "\n",
    "        _, probas = nnet.forward(features)\n",
    "        predicted_labels = np.argmax(probas, axis=1)\n",
    "        \n",
    "        onehot_targets = int_to_onehot(targets, num_labels=num_labels)\n",
    "        loss = np.mean((onehot_targets - probas)**2)\n",
    "        correct_pred += (predicted_labels == targets).sum()\n",
    "        \n",
    "        num_examples += targets.shape[0]\n",
    "        mse += loss\n",
    "\n",
    "    mse = mse/i\n",
    "    acc = correct_pred/num_examples\n",
    "    return mse, acc\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "mse, acc = compute_mse_and_acc(model, X_valid, y_valid)\n",
    "print(f'Initial valid MSE: {mse:.1f}')\n",
    "print(f'Initial valid accuracy: {acc*100:.1f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/gh/_rn0mj6977n_tj3zkksxl7mc0000gn/T/ipykernel_17444/2250388816.py:5: RuntimeWarning: overflow encountered in exp\n",
      "  return 1. / (1. + np.exp(-z))\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'NeuralNetMLP' object has no attribute 'weight_out'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[35], line 48\u001b[0m\n\u001b[1;32m     41\u001b[0m     \u001b[39mreturn\u001b[39;00m epoch_loss, epoch_train_acc, epoch_valid_acc\n\u001b[1;32m     46\u001b[0m np\u001b[39m.\u001b[39mrandom\u001b[39m.\u001b[39mseed(\u001b[39m123\u001b[39m) \u001b[39m# for the training set shuffling\u001b[39;00m\n\u001b[0;32m---> 48\u001b[0m epoch_loss, epoch_train_acc, epoch_valid_acc \u001b[39m=\u001b[39m train(\n\u001b[1;32m     49\u001b[0m     model, X_train, y_train, X_valid, y_valid,\n\u001b[1;32m     50\u001b[0m     num_epochs\u001b[39m=\u001b[39m\u001b[39m50\u001b[39m, learning_rate\u001b[39m=\u001b[39m\u001b[39m0.1\u001b[39m)\n\u001b[1;32m     53\u001b[0m \u001b[39m# ## Evaluating the neural network performance\u001b[39;00m\n\u001b[1;32m     57\u001b[0m plt\u001b[39m.\u001b[39mplot(\u001b[39mrange\u001b[39m(\u001b[39mlen\u001b[39m(epoch_loss)), epoch_loss)\n",
      "Cell \u001b[0;32mIn[35], line 21\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(model, X_train, y_train, X_valid, y_valid, num_epochs, learning_rate)\u001b[0m\n\u001b[1;32m     17\u001b[0m a_h, a_out \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39mforward(X_train_mini)\n\u001b[1;32m     19\u001b[0m \u001b[39m#### Compute gradients ####\u001b[39;00m\n\u001b[1;32m     20\u001b[0m d_loss__d_w_out, d_loss__d_b_out, d_loss__d_w_h, d_loss__d_b_h \u001b[39m=\u001b[39m \\\n\u001b[0;32m---> 21\u001b[0m     model\u001b[39m.\u001b[39mbackward(X_train_mini, a_h, a_out, y_train_mini)\n\u001b[1;32m     23\u001b[0m \u001b[39m#### Update weights ####\u001b[39;00m\n\u001b[1;32m     24\u001b[0m model\u001b[39m.\u001b[39mweight_h \u001b[39m-\u001b[39m\u001b[39m=\u001b[39m learning_rate \u001b[39m*\u001b[39m d_loss__d_w_h\n",
      "Cell \u001b[0;32mIn[31], line 86\u001b[0m, in \u001b[0;36mNeuralNetMLP.backward\u001b[0;34m(self, x, a_h, a_out, y)\u001b[0m\n\u001b[1;32m     78\u001b[0m d_loss__db_out \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39msum(delta_out, axis\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m)\n\u001b[1;32m     81\u001b[0m \u001b[39m#################################        \u001b[39;00m\n\u001b[1;32m     82\u001b[0m \u001b[39m# Part 2: dLoss/dHiddenWeights\u001b[39;00m\n\u001b[1;32m     83\u001b[0m \u001b[39m## = DeltaOut * dOutNet/dHiddenAct * dHiddenAct/dHiddenNet * dHiddenNet/dWeight\u001b[39;00m\n\u001b[1;32m     84\u001b[0m \n\u001b[1;32m     85\u001b[0m \u001b[39m# [n_classes, n_hidden]\u001b[39;00m\n\u001b[0;32m---> 86\u001b[0m d_z_out__a_h \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mweight_out\n\u001b[1;32m     88\u001b[0m \u001b[39m# output dim: [n_examples, n_hidden]\u001b[39;00m\n\u001b[1;32m     89\u001b[0m d_loss__a_h \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mdot(delta_out, d_z_out__a_h)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'NeuralNetMLP' object has no attribute 'weight_out'"
     ]
    }
   ],
   "source": [
    "def train(model, X_train, y_train, X_valid, y_valid, num_epochs,\n",
    "          learning_rate=0.1):\n",
    "    \n",
    "    epoch_loss = []\n",
    "    epoch_train_acc = []\n",
    "    epoch_valid_acc = []\n",
    "    \n",
    "    for e in range(num_epochs):\n",
    "\n",
    "        # iterate over minibatches\n",
    "        minibatch_gen = minibatch_generator(\n",
    "            X_train, y_train, minibatch_size)\n",
    "\n",
    "        for X_train_mini, y_train_mini in minibatch_gen:\n",
    "            \n",
    "            #### Compute outputs ####\n",
    "            a_h, a_out = model.forward(X_train_mini)\n",
    "\n",
    "            #### Compute gradients ####\n",
    "            d_loss__d_w_out, d_loss__d_b_out, d_loss__d_w_h, d_loss__d_b_h = \\\n",
    "                model.backward(X_train_mini, a_h, a_out, y_train_mini)\n",
    "\n",
    "            #### Update weights ####\n",
    "            model.weight_h -= learning_rate * d_loss__d_w_h\n",
    "            model.bias_h -= learning_rate * d_loss__d_b_h\n",
    "            model.weight_out -= learning_rate * d_loss__d_w_out\n",
    "            model.bias_out -= learning_rate * d_loss__d_b_out\n",
    "        \n",
    "        #### Epoch Logging ####        \n",
    "        train_mse, train_acc = compute_mse_and_acc(model, X_train, y_train)\n",
    "        valid_mse, valid_acc = compute_mse_and_acc(model, X_valid, y_valid)\n",
    "        train_acc, valid_acc = train_acc*100, valid_acc*100\n",
    "        epoch_train_acc.append(train_acc)\n",
    "        epoch_valid_acc.append(valid_acc)\n",
    "        epoch_loss.append(train_mse)\n",
    "        print(f'Epoch: {e+1:03d}/{num_epochs:03d} '\n",
    "              f'| Train MSE: {train_mse:.2f} '\n",
    "              f'| Train Acc: {train_acc:.2f}% '\n",
    "              f'| Valid Acc: {valid_acc:.2f}%')\n",
    "\n",
    "    return epoch_loss, epoch_train_acc, epoch_valid_acc\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "np.random.seed(123) # for the training set shuffling\n",
    "\n",
    "epoch_loss, epoch_train_acc, epoch_valid_acc = train(\n",
    "    model, X_train, y_train, X_valid, y_valid,\n",
    "    num_epochs=50, learning_rate=0.1)\n",
    "\n",
    "\n",
    "# ## Evaluating the neural network performance\n",
    "\n",
    "\n",
    "\n",
    "plt.plot(range(len(epoch_loss)), epoch_loss)\n",
    "plt.ylabel('Mean squared error')\n",
    "plt.xlabel('Epoch')\n",
    "#plt.savefig('figures/11_07.png', dpi=300)\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "plt.plot(range(len(epoch_train_acc)), epoch_train_acc,\n",
    "         label='Training')\n",
    "plt.plot(range(len(epoch_valid_acc)), epoch_valid_acc,\n",
    "         label='Validation')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.legend(loc='lower right')\n",
    "#plt.savefig('figures/11_08.png', dpi=300)\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "test_mse, test_acc = compute_mse_and_acc(model, X_test, y_test)\n",
    "print(f'Test accuracy: {test_acc*100:.2f}%')\n",
    "\n",
    "\n",
    "# Plot failure cases:\n",
    "\n",
    "\n",
    "\n",
    "X_test_subset = X_test[:1000, :]\n",
    "y_test_subset = y_test[:1000]\n",
    "\n",
    "_, probas = model.forward(X_test_subset)\n",
    "test_pred = np.argmax(probas, axis=1)\n",
    "\n",
    "misclassified_images = X_test_subset[y_test_subset != test_pred][:25]\n",
    "misclassified_labels = test_pred[y_test_subset != test_pred][:25]\n",
    "correct_labels = y_test_subset[y_test_subset != test_pred][:25]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots(nrows=5, ncols=5, \n",
    "                       sharex=True, sharey=True, figsize=(8, 8))\n",
    "ax = ax.flatten()\n",
    "for i in range(25):\n",
    "    img = misclassified_images[i].reshape(28, 28)\n",
    "    ax[i].imshow(img, cmap='Greys', interpolation='nearest')\n",
    "    ax[i].set_title(f'{i+1}) '\n",
    "                    f'True: {correct_labels[i]}\\n'\n",
    "                    f' Predicted: {misclassified_labels[i]}')\n",
    "\n",
    "ax[0].set_xticks([])\n",
    "ax[0].set_yticks([])\n",
    "plt.tight_layout()\n",
    "#plt.savefig('figures/11_09.png', dpi=300)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3_11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
